"""
FastAPI endpoints for the RCAccelerator API.
"""
from typing import Dict, Any
from fastapi import FastAPI
from pydantic import BaseModel, Field
from chat import handle_user_message_api
from config import config
from settings import ModelSettings
from vectordb import vector_store
from generation import discover_generative_model_names
from embeddings import discover_embeddings_model_names

app = FastAPI(title="RCAccelerator API")


class ChatRequest(BaseModel):
    """
    Represents the parameters for a chat request, including
    message content, similarity threshold, temperature, and max token limit.
    """
    content: str
    similarity_threshold: float = Field(
        config.search_similarity_threshold,
        gt=0.0,
        le=1.0
        )
    temperature: float = Field(
        config.default_temperature,
        gt=0.1,
        le=1.0
    )
    max_tokens: int = Field(
        config.default_max_tokens,
        gt=1,
        le=1024
    )
    vectordb_collection: str = Field(
        config.vectordb_collection_name,
        description="The name of the vector database collection to use."
    )
    generative_model_name: str = Field(
        config.generative_model,
        description="The name of the generative model to use."
    )
    embeddings_model_name: str = Field(
        config.embeddings_model,
        description="The name of the embeddings model to use."
    )


@app.post("/prompt")
async def process_prompt(message_data: ChatRequest) -> Dict[str, Any]:
    """
    FastAPI endpoint that processes a message and returns an answer.

    Args:
        message_data: BaseModel class containing the message content

    Returns:
        The response generated by the chat handler
    """

    generative_model_settings: ModelSettings = {
        "model": message_data.generative_model_name,
        "max_tokens": message_data.max_tokens,
        "temperature": message_data.temperature,
    }
    embeddings_model_settings: ModelSettings = {
        "model": message_data.embeddings_model_name,
    }

    available_collections, _ = vector_store.get_collection_settings()
    if message_data.vectordb_collection not in available_collections:
        return {
            "error": f"Invalid collection name. Available collections are: {available_collections}"
        }
    available_generative_models = await discover_generative_model_names()
    if message_data.generative_model_name not in available_generative_models:
        return {
            "error": "Invalid generative model name. " +
            f"Available models are: {available_generative_models}"
        }
    available_embeddings_models = await discover_embeddings_model_names()
    if message_data.embeddings_model_name not in available_embeddings_models:
        return {
            "error": "Invalid embeddings model name. " +
            f"Available models are: {available_embeddings_models}"
        }

    response = await handle_user_message_api(
        message_data.content,
        message_data.similarity_threshold,
        generative_model_settings,
        embeddings_model_settings,
        message_data.vectordb_collection,
        )

    return  {
        "response": getattr(response, "content", ""),
        "urls": getattr(response, "urls", [])
    }
